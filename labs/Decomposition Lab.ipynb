{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3a_moving_averages.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZacharySBrown/vcu-scma440-2021q1/blob/master/labs/Decomposition%20Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ_yQDFX3cal"
      },
      "source": [
        "# Setup and Fetch Data\n",
        "\n",
        "Press the play button in Google Colab or press `Shift+Enter` execute the cell below to download and load the data and packages for this assignment\n",
        "\n",
        "This will load four `pandas` `DataFrame` objects: `shampoo`,`housing`, `airline`, and `airline_series`.\n",
        "Each of these is used in Makridakis Chapter 3. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIlYFk6o3cat",
        "outputId": "78e03951-cf48-45d8-d20e-bac548261024"
      },
      "source": [
        "import pandas as pd\n",
        "from numpy import log, abs, mean, exp\n",
        "from IPython.display import display\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 16\n",
        "\n",
        "!curl https://raw.githubusercontent.com/ZacharySBrown/vcu-scma440-2021q1/master/utils/fetch_e3.sh > fetch_e3.sh\n",
        "!bash fetch_e3.sh\n",
        "\n",
        "# Example\n",
        "shampoo = pd.read_csv('shampoo_sales.csv', parse_dates=['date']).set_index('date')\n",
        "housing = pd.read_csv('housing_sales.csv', parse_dates=['date']).set_index('date')\n",
        "airline = pd.read_csv('airline.csv').set_index('year')\n",
        "airline_series = pd.read_csv('airline_series.csv', parse_dates=['date']).set_index('date')\n",
        "\n",
        "!pip install -U statsmodels\n",
        "\n",
        "from statsmodels.nonparametric.smoothers_lowess import lowess"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   380  100   380    0     0   4175      0 --:--:-- --:--:-- --:--:--  4175\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   629  100   629    0     0   5376      0 --:--:-- --:--:-- --:--:--  5376\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3867  100  3867    0     0  37543      0 --:--:-- --:--:-- --:--:-- 37543\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   456  100   456    0     0   4851      0 --:--:-- --:--:-- --:--:--  4800\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1456  100  1456    0     0  13607      0 --:--:-- --:--:-- --:--:-- 13607\n",
            "Requirement already up-to-date: statsmodels in /opt/miniconda3/lib/python3.7/site-packages (0.12.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15 in /opt/miniconda3/lib/python3.7/site-packages (from statsmodels) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.1 in /opt/miniconda3/lib/python3.7/site-packages (from statsmodels) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21 in /opt/miniconda3/lib/python3.7/site-packages (from statsmodels) (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: patsy>=0.5 in /opt/miniconda3/lib/python3.7/site-packages (from statsmodels) (0.5.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /opt/miniconda3/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /opt/miniconda3/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2019.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /opt/miniconda3/lib/python3.7/site-packages (from patsy>=0.5->statsmodels) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iG2HDkp3hEM"
      },
      "source": [
        "# 1: Moving Averages\n",
        "\n",
        "1. Create **3MA**, **5MA**, and **7MA** smoothers for the airline data and plot\n",
        "2. Create **2x12MA*, **2x24MA**, and **2x36MA** smoothers for the housing data and plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJDPW1mS33Ai"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4b518HA37OS"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyC5tnKd4KM_",
        "outputId": "98ef1076-9d46-4a9f-b8ab-77dc6ab4b2d6"
      },
      "source": [
        "# 2. Local Smoothing\n",
        "\n",
        "\n",
        "* Calculate a local LOWESS smoother for the `airline_series` data and plot\n",
        "* Try this out for various values of `frac`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU6wUUj5xvSo"
      },
      "source": [
        "# Start by reloading the `airline_series` data so you have a fresh copy\n",
        "airline_series = pd.read_csv('airline_series.csv', parse_dates=['date']).set_index('date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pstiu6RD4MoK"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ulAxTWb4QQl"
      },
      "source": [
        "# 3. Decomposition\n",
        "\n",
        "Carry out an additive decomposition for the housing data, but this time use a LOWESS smoother to calculate the trend-cycle. \n",
        "\n",
        "1. Calculate the trend cycle using LOWESS, choosing an appropriate value for `frac`. Make sure to plot to check you're not over smoothing\n",
        "2. De-trend the data\n",
        "3. Calculate the seasonal indices, and repeat them to create the full seasonal series\n",
        "4. Calculate the irregular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT5f3uhQBd5S"
      },
      "source": [
        "# Start by reloading the housing data\n",
        "housing = pd.read_csv('housing_sales.csv', parse_dates=['date']).set_index('date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJB1VQuqxvSp"
      },
      "source": [
        "## Trend-cycle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9045EOYYxvSp"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOanWtivxvSp"
      },
      "source": [
        "## Detrended"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssWhhDhBxvSq"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go-cxDqMxvSq"
      },
      "source": [
        "## Seasonal Indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYwoxOHfxvSq"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbMloEsPxvSq"
      },
      "source": [
        "## Seasonal Component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFU20ZbbxvSq"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgEjB_WxvSq"
      },
      "source": [
        "## Irregular"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ED49ItgxvSr"
      },
      "source": [
        "# YOUR CODE HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}